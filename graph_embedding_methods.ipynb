{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ML Graph Embedding methods",
   "id": "7d4d3767eac7daa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.680080Z",
     "start_time": "2024-10-02T23:26:11.676697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import libraries\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec"
   ],
   "id": "2b896f263ab1b657",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.710588Z",
     "start_time": "2024-10-02T23:26:11.688691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the graph from the file\n",
    "server_graph_data_filepath = './data/server_graph_data.pth'\n",
    "graph_data = torch.load(server_graph_data_filepath)"
   ],
   "id": "9ff9f7416e1f5cb2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10880\\4280630462.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load(server_graph_data_filepath)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.828942Z",
     "start_time": "2024-10-02T23:26:11.789368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "graph_data = graph_data.to(device)"
   ],
   "id": "7278aa25577143a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-03T00:56:53.173388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Node2Vec model\n",
    "node2vec = Node2Vec(\n",
    "    graph_data.edge_index,       # Edge list\n",
    "    embedding_dim=3,      # Size of embeddings\n",
    "    walk_length=20,        # Length of each random walk\n",
    "    context_size=10,       # Window size for Skip-Gram\n",
    "    walks_per_node=10,     # Number of walks per node\n",
    "    num_negative_samples=1,  # Number of negative samples for Skip-Gram\n",
    "    p=0.25,  # Return parameter: encourages staying close to the starting node\n",
    "    q=4.0,   # In-out parameter: encourages exploring further away\n",
    "    sparse=True            # Use sparse gradients for efficiency\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    node2vec.train()\n",
    "    total_loss = 0\n",
    "    loader = node2vec.loader(batch_size=128, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = node2vec.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ],
   "id": "736ecc99c3d65eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:56:23.330609Z",
     "start_time": "2024-10-03T00:56:23.326378Z"
    }
   },
   "cell_type": "code",
   "source": "node_embeddings",
   "id": "e450e8c299278035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1956, -0.0389, -0.1859,  ...,  0.0475, -0.0884, -0.0699],\n",
       "        [-0.0690, -0.0156, -0.1036,  ...,  0.1697,  0.0661, -0.0776],\n",
       "        [-0.0579, -0.1316, -0.0748,  ..., -0.0214,  0.0254,  0.0597],\n",
       "        ...,\n",
       "        [ 0.1938, -0.1235, -0.2061,  ..., -0.1346, -0.0255,  0.0340],\n",
       "        [-0.2151, -0.1955,  0.2303,  ..., -0.2078, -0.7202,  0.2727],\n",
       "        [ 0.0382, -0.0080,  0.0493,  ..., -0.0646, -0.0192, -0.0469]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:04:35.555171Z",
     "start_time": "2024-10-02T23:36:00.693900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the DeepWalk model by setting p and q to 1 (unbiased random walks)\n",
    "deepwalk = Node2Vec(\n",
    "    graph_data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=40,        # Longer walk length for DeepWalk\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    sparse=True\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(deepwalk.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    deepwalk.train()\n",
    "    total_loss = 0\n",
    "    loader = deepwalk.loader(batch_size=128, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = deepwalk.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings_deepwalk = deepwalk.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ],
   "id": "2821ca37293a722a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.7447\n",
      "Epoch: 020, Loss: 0.7291\n",
      "Epoch: 030, Loss: 0.7280\n",
      "Epoch: 040, Loss: 0.7271\n",
      "Epoch: 050, Loss: 0.7272\n",
      "Epoch: 060, Loss: 0.7271\n",
      "Epoch: 070, Loss: 0.7266\n",
      "Epoch: 080, Loss: 0.7260\n",
      "Epoch: 090, Loss: 0.7252\n",
      "Epoch: 100, Loss: 0.7248\n",
      "Node Embeddings Shape: torch.Size([5541, 64])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:53:18.273258Z",
     "start_time": "2024-10-03T00:53:18.250227Z"
    }
   },
   "cell_type": "code",
   "source": "node_embeddings_deepwalk",
   "id": "c618b7b4ef640b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0688,  0.0457,  0.0361,  ..., -0.1405,  0.0154,  0.0034],\n",
       "        [ 0.0852,  0.0159,  0.0223,  ...,  0.0041,  0.0731, -0.0527],\n",
       "        [-0.2004,  0.0200, -0.0227,  ...,  0.1094, -0.0901,  0.0482],\n",
       "        ...,\n",
       "        [-0.0477, -0.0120,  0.0903,  ...,  0.1099,  0.0656,  0.0857],\n",
       "        [-0.1605,  0.3507,  0.3372,  ..., -0.0079,  0.1192, -0.3012],\n",
       "        [-0.0349, -0.0330,  0.0404,  ..., -0.0570,  0.0777,  0.0656]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f810259faae551e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
