{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ML Graph Embedding methods",
   "id": "7d4d3767eac7daa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.680080Z",
     "start_time": "2024-10-02T23:26:11.676697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import libraries\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec"
   ],
   "id": "2b896f263ab1b657",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.710588Z",
     "start_time": "2024-10-02T23:26:11.688691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the graph from the file\n",
    "server_graph_data_filepath = './data/server_graph_data.pth'\n",
    "graph_data = torch.load(server_graph_data_filepath)"
   ],
   "id": "9ff9f7416e1f5cb2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_10880\\4280630462.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load(server_graph_data_filepath)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T23:26:11.828942Z",
     "start_time": "2024-10-02T23:26:11.789368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "graph_data = graph_data.to(device)"
   ],
   "id": "7278aa25577143a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T01:33:16.313260Z",
     "start_time": "2024-10-03T00:56:53.173388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Node2Vec model\n",
    "node2vec = Node2Vec(\n",
    "    graph_data.edge_index,       # Edge list\n",
    "    embedding_dim=3,      # Size of embeddings\n",
    "    walk_length=20,        # Length of each random walk\n",
    "    context_size=10,       # Window size for Skip-Gram\n",
    "    walks_per_node=10,     # Number of walks per node\n",
    "    num_negative_samples=1,  # Number of negative samples for Skip-Gram\n",
    "    p=0.25,  # Return parameter: encourages staying close to the starting node\n",
    "    q=4.0,   # In-out parameter: encourages exploring further away\n",
    "    sparse=True            # Use sparse gradients for efficiency\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    node2vec.train()\n",
    "    total_loss = 0\n",
    "    loader = node2vec.loader(batch_size=128, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = node2vec.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ],
   "id": "736ecc99c3d65eaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.8173\n",
      "Epoch: 020, Loss: 0.7962\n",
      "Epoch: 030, Loss: 0.7870\n",
      "Epoch: 040, Loss: 0.7814\n",
      "Epoch: 050, Loss: 0.7771\n",
      "Epoch: 060, Loss: 0.7722\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 32\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# Run training for multiple epochs\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m101\u001B[39m):\n\u001B[1;32m---> 32\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[12], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     21\u001B[0m loader \u001B[38;5;241m=\u001B[39m node2vec\u001B[38;5;241m.\u001B[39mloader(batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 22\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpos_rw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_rw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnode2vec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpos_rw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_rw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    672\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 673\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    674\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    675\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:140\u001B[0m, in \u001B[0;36mNode2Vec.sample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch, Tensor):\n\u001B[0;32m    139\u001B[0m     batch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(batch)\n\u001B[1;32m--> 140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneg_sample(batch)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:111\u001B[0m, in \u001B[0;36mNode2Vec.pos_sample\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpos_sample\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    110\u001B[0m     batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mrepeat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwalks_per_node)\n\u001B[1;32m--> 111\u001B[0m     rw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_walk_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrowptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m                             \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwalk_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rw, Tensor):\n\u001B[0;32m    114\u001B[0m         rw \u001B[38;5;241m=\u001B[39m rw[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\graph_attack_defend_games_ml\\venv\\Lib\\site-packages\\torch\\_ops.py:1061\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[1;34m(self_, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m self_\u001B[38;5;241m.\u001B[39m_has_torchbind_op_overload \u001B[38;5;129;01mand\u001B[39;00m _must_dispatch_in_python(args, kwargs):\n\u001B[0;32m   1060\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001B[1;32m-> 1061\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mself_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:56:23.330609Z",
     "start_time": "2024-10-03T00:56:23.326378Z"
    }
   },
   "cell_type": "code",
   "source": "node_embeddings",
   "id": "e450e8c299278035",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1956, -0.0389, -0.1859,  ...,  0.0475, -0.0884, -0.0699],\n",
       "        [-0.0690, -0.0156, -0.1036,  ...,  0.1697,  0.0661, -0.0776],\n",
       "        [-0.0579, -0.1316, -0.0748,  ..., -0.0214,  0.0254,  0.0597],\n",
       "        ...,\n",
       "        [ 0.1938, -0.1235, -0.2061,  ..., -0.1346, -0.0255,  0.0340],\n",
       "        [-0.2151, -0.1955,  0.2303,  ..., -0.2078, -0.7202,  0.2727],\n",
       "        [ 0.0382, -0.0080,  0.0493,  ..., -0.0646, -0.0192, -0.0469]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:04:35.555171Z",
     "start_time": "2024-10-02T23:36:00.693900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the DeepWalk model by setting p and q to 1 (unbiased random walks)\n",
    "deepwalk = Node2Vec(\n",
    "    graph_data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=40,        # Longer walk length for DeepWalk\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    sparse=True\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(deepwalk.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    deepwalk.train()\n",
    "    total_loss = 0\n",
    "    loader = deepwalk.loader(batch_size=128, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = deepwalk.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings_deepwalk = deepwalk.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ],
   "id": "2821ca37293a722a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.7447\n",
      "Epoch: 020, Loss: 0.7291\n",
      "Epoch: 030, Loss: 0.7280\n",
      "Epoch: 040, Loss: 0.7271\n",
      "Epoch: 050, Loss: 0.7272\n",
      "Epoch: 060, Loss: 0.7271\n",
      "Epoch: 070, Loss: 0.7266\n",
      "Epoch: 080, Loss: 0.7260\n",
      "Epoch: 090, Loss: 0.7252\n",
      "Epoch: 100, Loss: 0.7248\n",
      "Node Embeddings Shape: torch.Size([5541, 64])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T00:53:18.273258Z",
     "start_time": "2024-10-03T00:53:18.250227Z"
    }
   },
   "cell_type": "code",
   "source": "node_embeddings_deepwalk",
   "id": "c618b7b4ef640b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0688,  0.0457,  0.0361,  ..., -0.1405,  0.0154,  0.0034],\n",
       "        [ 0.0852,  0.0159,  0.0223,  ...,  0.0041,  0.0731, -0.0527],\n",
       "        [-0.2004,  0.0200, -0.0227,  ...,  0.1094, -0.0901,  0.0482],\n",
       "        ...,\n",
       "        [-0.0477, -0.0120,  0.0903,  ...,  0.1099,  0.0656,  0.0857],\n",
       "        [-0.1605,  0.3507,  0.3372,  ..., -0.0079,  0.1192, -0.3012],\n",
       "        [-0.0349, -0.0330,  0.0404,  ..., -0.0570,  0.0777,  0.0656]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f810259faae551e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
