{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4d3767eac7daa5",
   "metadata": {},
   "source": [
    "# ML Graph Embedding methods"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b896f263ab1b657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:31:27.377930Z",
     "start_time": "2024-10-16T05:31:24.810005Z"
    }
   },
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import time\n",
    "from torch_geometric.nn import Node2Vec"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:31:27.388935Z",
     "start_time": "2024-10-16T05:31:27.384934Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.version.cuda)",
   "id": "a12d5d9509c1d903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9ff9f7416e1f5cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:31:28.597184Z",
     "start_time": "2024-10-16T05:31:27.535424Z"
    }
   },
   "source": [
    "# Load the graph from the file\n",
    "server_graph_data_filepath = './data/server_graph_data.pth'\n",
    "graph_data = torch.load(server_graph_data_filepath)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_26188\\4280630462.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load(server_graph_data_filepath)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "7278aa25577143a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:31:28.797360Z",
     "start_time": "2024-10-16T05:31:28.606189Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "graph_data = graph_data.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "736ecc99c3d65eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T08:51:32.078245Z",
     "start_time": "2024-10-16T05:31:28.810491Z"
    }
   },
   "source": [
    "# Initialize the Node2Vec model\n",
    "node2vec = Node2Vec(\n",
    "    graph_data.edge_index,       # Edge list\n",
    "    embedding_dim=3,      # Size of embeddings\n",
    "    walk_length=20,        # Length of each random walk\n",
    "    context_size=10,       # Window size for Skip-Gram\n",
    "    walks_per_node=10,     # Number of walks per node\n",
    "    num_negative_samples=1,  # Number of negative samples for Skip-Gram\n",
    "    p=0.25,  # Return parameter: encourages staying close to the starting node\n",
    "    q=4.0,   # In-out parameter: encourages exploring further away\n",
    "    sparse=True            # Use sparse gradients for efficiency\n",
    ").to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    node2vec.train()\n",
    "    total_loss = 0\n",
    "    loader = node2vec.loader(batch_size=8, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        pos_rw = pos_rw.to(device)\n",
    "        neg_rw = neg_rw.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = node2vec.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    # Save timestamp\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    # Save timestamp\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.73618745803833\n",
      "130.99125599861145\n",
      "129.40948152542114\n",
      "127.02247142791748\n",
      "124.91007542610168\n",
      "123.32488918304443\n",
      "121.82983803749084\n",
      "121.6709771156311\n",
      "121.91338753700256\n",
      "Epoch: 010, Loss: 0.7759\n",
      "121.6263575553894\n",
      "121.31929612159729\n",
      "121.51817274093628\n",
      "120.66063284873962\n",
      "120.74512791633606\n",
      "120.56543374061584\n",
      "120.4960515499115\n",
      "120.55703234672546\n",
      "120.96491742134094\n",
      "120.94094729423523\n",
      "Epoch: 020, Loss: 0.7695\n",
      "120.7212336063385\n",
      "120.11761331558228\n",
      "120.26626205444336\n",
      "120.29437780380249\n",
      "120.40866780281067\n",
      "120.33241963386536\n",
      "119.86544489860535\n",
      "119.94821524620056\n",
      "120.18908286094666\n",
      "119.97679734230042\n",
      "Epoch: 030, Loss: 0.7690\n",
      "119.84493684768677\n",
      "119.8982183933258\n",
      "120.04901552200317\n",
      "119.38574004173279\n",
      "119.92442488670349\n",
      "120.31553220748901\n",
      "120.44609451293945\n",
      "119.51584243774414\n",
      "119.482337474823\n",
      "119.26975631713867\n",
      "Epoch: 040, Loss: 0.7683\n",
      "119.60675239562988\n",
      "119.69831418991089\n",
      "119.157066822052\n",
      "119.69274067878723\n",
      "119.18375968933105\n",
      "119.0699234008789\n",
      "119.5644862651825\n",
      "120.14952087402344\n",
      "118.92179465293884\n",
      "119.7735002040863\n",
      "Epoch: 050, Loss: 0.7689\n",
      "119.50051140785217\n",
      "119.47914600372314\n",
      "119.06131839752197\n",
      "118.94172525405884\n",
      "119.05656719207764\n",
      "119.09920120239258\n",
      "119.12861657142639\n",
      "118.99783754348755\n",
      "118.61359238624573\n",
      "119.53363990783691\n",
      "Epoch: 060, Loss: 0.7681\n",
      "118.98512721061707\n",
      "118.98502135276794\n",
      "119.03874206542969\n",
      "118.40568137168884\n",
      "119.57290625572205\n",
      "118.65583395957947\n",
      "119.12927603721619\n",
      "119.70901727676392\n",
      "118.47395825386047\n",
      "118.86377501487732\n",
      "Epoch: 070, Loss: 0.7680\n",
      "118.86126375198364\n",
      "119.41077089309692\n",
      "118.70000290870667\n",
      "119.27619409561157\n",
      "119.1635594367981\n",
      "118.83171820640564\n",
      "118.98478150367737\n",
      "118.65598797798157\n",
      "118.34581780433655\n",
      "118.81065893173218\n",
      "Epoch: 080, Loss: 0.7673\n",
      "118.31055068969727\n",
      "119.01634311676025\n",
      "118.84899544715881\n",
      "118.69596791267395\n",
      "119.39241695404053\n",
      "118.37528276443481\n",
      "118.42437410354614\n",
      "118.92548727989197\n",
      "118.66361975669861\n",
      "118.5916178226471\n",
      "Epoch: 090, Loss: 0.7679\n",
      "118.34522032737732\n",
      "118.71281838417053\n",
      "118.80673837661743\n",
      "118.6403226852417\n",
      "118.3110659122467\n",
      "118.86224365234375\n",
      "118.4038610458374\n",
      "118.94567704200745\n",
      "118.40811681747437\n",
      "118.44881224632263\n",
      "Epoch: 100, Loss: 0.7672\n",
      "118.50253891944885\n",
      "Node Embeddings Shape: torch.Size([19129, 3])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "e450e8c299278035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T08:51:32.112275Z",
     "start_time": "2024-10-16T08:51:32.104653Z"
    }
   },
   "source": [
    "node_embeddings"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1627,  0.0256,  0.1298],\n",
       "        [-0.2320, -0.0875,  0.1060],\n",
       "        [-0.2535,  0.3937,  0.0748],\n",
       "        ...,\n",
       "        [-0.1484, -0.1693, -0.0323],\n",
       "        [ 1.7283, -0.0232, -0.8917],\n",
       "        [-0.1192, -0.2461,  0.0336]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1d5cba2c65ded4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T08:51:32.153006Z",
     "start_time": "2024-10-16T08:51:32.148687Z"
    }
   },
   "source": [
    "node2vector_embedding_filepath = 'node2vector_embeddings.pt'\n",
    "torch.save(node_embeddings, node2vector_embedding_filepath)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "2821ca37293a722a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:33:01.113092Z",
     "start_time": "2024-10-16T11:22:20.398470Z"
    }
   },
   "source": [
    "# Initialize the DeepWalk model by setting p and q to 1 (unbiased random walks)\n",
    "deepwalk = Node2Vec(\n",
    "    graph_data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=40, # Longer walk length for DeepWalk\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    sparse=True\n",
    ").to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(deepwalk.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    deepwalk.train()\n",
    "    total_loss = 0\n",
    "    loader = deepwalk.loader(batch_size=8, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        pos_rw = pos_rw.to(device)\n",
    "        neg_rw = neg_rw.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = deepwalk.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        \n",
    "    # Save timestamp\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings_deepwalk = deepwalk.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings_deepwalk.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.767935037612915\n",
      "5.873707056045532\n",
      "6.007341623306274\n",
      "7.0716023445129395\n",
      "7.07146430015564\n",
      "7.120197057723999\n",
      "7.030393123626709\n",
      "7.1353559494018555\n",
      "7.134816884994507\n",
      "Epoch: 010, Loss: 0.7360\n",
      "7.025185823440552\n",
      "7.079774379730225\n",
      "7.025813817977905\n",
      "7.14076828956604\n",
      "7.079728841781616\n",
      "7.0712809562683105\n",
      "7.111080646514893\n",
      "7.058572769165039\n",
      "7.111705303192139\n",
      "7.0954365730285645\n",
      "Epoch: 020, Loss: 0.7288\n",
      "6.99012565612793\n",
      "7.09937858581543\n",
      "6.995908498764038\n",
      "7.118033170700073\n",
      "7.116052865982056\n",
      "7.028337717056274\n",
      "7.146016597747803\n",
      "7.083376884460449\n",
      "7.144520282745361\n",
      "7.165513515472412\n",
      "Epoch: 030, Loss: 0.7255\n",
      "6.93779730796814\n",
      "7.138479709625244\n",
      "7.085843801498413\n",
      "7.058143854141235\n",
      "7.117651462554932\n",
      "7.010565280914307\n",
      "7.082873106002808\n",
      "7.090676784515381\n",
      "7.058588743209839\n",
      "7.075692176818848\n",
      "Epoch: 040, Loss: 0.7240\n",
      "7.000749349594116\n",
      "7.124554872512817\n",
      "7.134103298187256\n",
      "7.064037799835205\n",
      "7.0668556690216064\n",
      "6.922300100326538\n",
      "7.085397243499756\n",
      "7.281412124633789\n",
      "7.504371166229248\n",
      "7.128816843032837\n",
      "Epoch: 050, Loss: 0.7240\n",
      "7.195823431015015\n",
      "7.01499605178833\n",
      "7.038980007171631\n",
      "7.223348617553711\n",
      "6.892747163772583\n",
      "5.824520587921143\n",
      "5.56989312171936\n",
      "5.769481182098389\n",
      "5.8810875415802\n",
      "5.659395933151245\n",
      "Epoch: 060, Loss: 0.7243\n",
      "5.9970502853393555\n",
      "5.751132011413574\n",
      "5.790219783782959\n",
      "5.7847230434417725\n",
      "5.550748825073242\n",
      "5.755197286605835\n",
      "5.556495428085327\n",
      "5.770253419876099\n",
      "5.747719764709473\n",
      "5.5204174518585205\n",
      "Epoch: 070, Loss: 0.7240\n",
      "5.959001064300537\n",
      "5.551775693893433\n",
      "5.729830741882324\n",
      "5.692571401596069\n",
      "5.601151943206787\n",
      "5.762880325317383\n",
      "5.804977178573608\n",
      "5.694270372390747\n",
      "5.727015256881714\n",
      "5.495397329330444\n",
      "Epoch: 080, Loss: 0.7241\n",
      "5.695235013961792\n",
      "5.772920846939087\n",
      "5.61786150932312\n",
      "5.728959798812866\n",
      "5.52345609664917\n",
      "5.6600730419158936\n",
      "5.676905632019043\n",
      "5.518146991729736\n",
      "5.683557987213135\n",
      "5.532115459442139\n",
      "Epoch: 090, Loss: 0.7239\n",
      "5.6850244998931885\n",
      "5.687671184539795\n",
      "5.5207061767578125\n",
      "5.849151134490967\n",
      "5.574754238128662\n",
      "5.712116479873657\n",
      "5.673418998718262\n",
      "5.50333309173584\n",
      "5.659547567367554\n",
      "5.505373239517212\n",
      "Epoch: 100, Loss: 0.7241\n",
      "5.667007207870483\n",
      "Node Embeddings Shape: torch.Size([19129, 64])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c618b7b4ef640b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:33:01.125594Z",
     "start_time": "2024-10-16T11:33:01.120095Z"
    }
   },
   "source": [
    "node_embeddings_deepwalk"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8289e-01,  2.0963e-01,  9.8698e-02,  ...,  1.5152e-02,\n",
       "         -1.9687e-01,  6.6291e-02],\n",
       "        [ 4.3452e-02, -2.3687e-01, -4.3718e-02,  ..., -6.0400e-02,\n",
       "         -7.0542e-02,  3.7939e-02],\n",
       "        [ 2.9276e-03, -1.3018e-01,  9.8565e-02,  ..., -4.3489e-02,\n",
       "         -2.1407e-01,  2.0897e-01],\n",
       "        ...,\n",
       "        [-4.0324e-02,  1.0460e-01,  4.2056e-02,  ...,  1.1005e-01,\n",
       "          6.1901e-02,  1.4247e-04],\n",
       "        [ 4.0746e-01, -4.9000e-01,  7.5014e-01,  ...,  2.6305e-01,\n",
       "         -1.2246e-02,  2.0184e-01],\n",
       "        [ 1.7585e-01, -1.7938e-01,  1.2310e-01,  ...,  1.9934e-01,\n",
       "         -4.7857e-03, -9.7514e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9f810259faae551e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T11:33:01.171445Z",
     "start_time": "2024-10-16T11:33:01.163123Z"
    }
   },
   "source": [
    "deepwalk_embedding_filepath = 'deepwalk_embeddings.pt'\n",
    "torch.save(node_embeddings_deepwalk, deepwalk_embedding_filepath)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "a0dc2f17a8a44e51",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
