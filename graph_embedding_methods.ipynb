{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4d3767eac7daa5",
   "metadata": {},
   "source": [
    "# ML Graph Embedding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b896f263ab1b657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.205215Z",
     "start_time": "2024-10-09T18:59:33.885675Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import time\n",
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff9f7416e1f5cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.626077Z",
     "start_time": "2024-10-09T18:59:35.208682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the graph from the file\n",
    "server_graph_data_filepath = './data/server_graph_data.pth'\n",
    "graph_data = torch.load(server_graph_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7278aa25577143a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.627342518Z",
     "start_time": "2024-10-09T12:55:07.715447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "graph_data = graph_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ecc99c3d65eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.627485379Z",
     "start_time": "2024-10-09T17:32:55.575605Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Node2Vec model\n",
    "node2vec = Node2Vec(\n",
    "    graph_data.edge_index,       # Edge list\n",
    "    embedding_dim=3,      # Size of embeddings\n",
    "    walk_length=20,        # Length of each random walk\n",
    "    context_size=10,       # Window size for Skip-Gram\n",
    "    walks_per_node=10,     # Number of walks per node\n",
    "    num_negative_samples=1,  # Number of negative samples for Skip-Gram\n",
    "    p=0.25,  # Return parameter: encourages staying close to the starting node\n",
    "    q=4.0,   # In-out parameter: encourages exploring further away\n",
    "    sparse=True            # Use sparse gradients for efficiency\n",
    ").to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    node2vec.train()\n",
    "    total_loss = 0\n",
    "    loader = node2vec.loader(batch_size=8, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        pos_rw = pos_rw.to(device)\n",
    "        neg_rw = neg_rw.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = node2vec.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    # Save timestamp\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    # Save timestamp\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450e8c299278035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.627723694Z",
     "start_time": "2024-10-09T16:46:05.624768Z"
    }
   },
   "outputs": [],
   "source": [
    "node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cba2c65ded4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.627896522Z",
     "start_time": "2024-10-09T16:47:27.802374Z"
    }
   },
   "outputs": [],
   "source": [
    "node2vector_embedding_filepath = 'node2vector_embeddings.pt'\n",
    "torch.save(node_embeddings, node2vector_embedding_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821ca37293a722a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.627974319Z",
     "start_time": "2024-10-09T17:24:00.554111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the DeepWalk model by setting p and q to 1 (unbiased random walks)\n",
    "deepwalk = Node2Vec(\n",
    "    graph_data.edge_index,\n",
    "    embedding_dim=64,\n",
    "    walk_length=40,        # Longer walk length for DeepWalk\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    sparse=True\n",
    ").to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(deepwalk.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    deepwalk.train()\n",
    "    total_loss = 0\n",
    "    loader = deepwalk.loader(batch_size=8, shuffle=True)\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        pos_rw = pos_rw.to(device)\n",
    "        neg_rw = neg_rw.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = deepwalk.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Run training for multiple epochs\n",
    "for epoch in range(1, 101):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "        \n",
    "    # Save timestamp\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "\n",
    "# Obtain the node embeddings\n",
    "node_embeddings_deepwalk = deepwalk.embedding.weight.data\n",
    "\n",
    "print(\"Node Embeddings Shape:\", node_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618b7b4ef640b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.628056134Z",
     "start_time": "2024-10-09T16:50:51.971438Z"
    }
   },
   "outputs": [],
   "source": [
    "node_embeddings_deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f810259faae551e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T18:59:35.628190027Z",
     "start_time": "2024-10-09T17:20:14.944699Z"
    }
   },
   "outputs": [],
   "source": [
    "deepwalk_embedding_filepath = 'deepwalk_embeddings.pt'\n",
    "torch.save(node_embeddings, deepwalk_embedding_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc2f17a8a44e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
